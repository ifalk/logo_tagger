POS correctes :

#melt:       165/442 = 37.33 %
melt:       342/442 = 77.38 %
#lg:         190/442 = 42.99 %
lg:         323/443 = 72.91 %
stanford:   376/442 = 85.07 %
#lia:        294/442 = 66.52 %
lia:        319/443 = 72.01 %
treetagger: 339/442 = 76.70 %
#semtag:      71/442 = 16.06 %
semtag:      291/443 = 65.69 %
talismane:   350/427 = 81.97 % (NC=NPP)

Melt score when NC=NPP: 83.48 % (369/442)



--------------------------------------------------

racolable arguably is adjective and not verb as in gold
stanford, melt and talismane all tag them as adjective



Stanford
===========

Maximum entropy cyclic dependency network

- explicit use of preceding and following tag contexts
   - bidirectional linear dependency network 
- use of lexical features 
- unknown word features

=> large number of feature => overfitting avoided with smoothing = quadratic penalisation (regularisation, Gaussian prior)
"Because penalties are effectively stronger for rare features than frequent ones, the presence of penalties increases the degree to which more general cross-word signature features (which apply to unknown words) are used, relative to word-specific sparse features (which do not apply to unknown words)."

Train & Test: FTB

tags: N, V, A, ADV, D, ET

proper vs. common noun?

MElt
======= 

MEMM with external lexical information (Lefff)

- no feature cutoff
- smoothing = gaussian regularisation


Train & Test: FTB

Tagset: 28 tags


TALISMANE
==========
