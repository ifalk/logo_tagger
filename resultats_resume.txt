POS correctes :

#melt:       165/442 = 37.33 %
melt:       342/442 = 77.38 %
#lg:         190/442 = 42.99 %
lg:         323/443 = 72.91 %
stanford:   376/442 = 85.07 %
#lia:        294/442 = 66.52 %
lia:        319/443 = 72.01 %
treetagger: 339/442 = 76.70 %
#semtag:      71/442 = 16.06 %
semtag:      291/443 = 65.69 %
talismane:   360/442 = 81.45 % (NC=NPP)

Melt score when NC=NPP: 83.48 % (369/442)

common nouns = proper nouns
25/03/2014
---------------------------

stanford   377/422 = 85.29 %
melt       368/442 = 83.26 %
lg 	   324/442 = 73.30 %
lia	   319/442 = 72.17 %
treetagger 339/442 = 76.70 %
semtag     291/442 = 65.84 %
talismane  360/442 = 81.45 %



--------------------------------------------------

racolable arguably is adjective and not verb as in gold
stanford, melt and talismane all tag them as adjective

vivre ensemble: gold-> nom, adverbe 
                melt, stanford, lg, talismane -> vinf, adverbe arguably ok
		lia -> NMS NMS
		sem_tag -> ADV _ADV
                tt ok
--------------------------------------------------

Islamo sceptique -> melt ADV ADJ
                 -> gold adj ?

Marie Chantaleries : GOLD -> np
TALISMANE : NC NPP
Melt : NPP NPP



Influence of tokenisation :
----------------------------

TALISMANE: no tokenisation at '-' -> pouvant-réadvenir are not split -> réadvenir is not recognised as verb.

Melt, stanford, sem-tag: same

lia : pouvant-réadvenir -> pouvant - réadvenir in preprocessing (IF)
      => réadvenir correctly tagged as verb.

lg: pouvant-réadvenir is split, réadvenir tagged as NC, - PONCT and pouvant VPR

TT: in tokenisation pouvant-réadvenir split into pouvant- and réadvenir because 'réadvenir' is marked as <neo> and TT can be told to ignore xml tags.

Remark
=========
In fact the neologism "réadvenir, verbe" is part of a second neologism "le pouvant-réadvenir" which is a common noun. Here only réadvenir is marked => change pouvant-réadvenir in edited xml file into "pouvant réadvenir" and rebuild sentence xml file.



Stanford
===========

Maximum entropy cyclic dependency network

- explicit use of preceding and following tag contexts
   - bidirectional linear dependency network 
- use of lexical features 
- unknown word features

=> large number of feature => overfitting avoided with smoothing = quadratic penalisation (regularisation, Gaussian prior)
"Because penalties are effectively stronger for rare features than frequent ones, the presence of penalties increases the degree to which more general cross-word signature features (which apply to unknown words) are used, relative to word-specific sparse features (which do not apply to unknown words)."

Train & Test: FTB

tags: N, V, A, ADV, D, ET

proper vs. common noun?

MElt
======= 

MEMM with external lexical information (Lefff)

- no feature cutoff
- smoothing = gaussian regularisation


Train & Test: FTB

Tagset: 28 tags


TALISMANE
==========
